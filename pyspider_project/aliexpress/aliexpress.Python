#!/usr/bin/env python
# -*- encoding: utf-8 -*-
# Created on:2016/3/13 22:07
# Project:aliexpress
# Author:yangmingsong_HOME

from pyspider.libs.base_handler import *
from ms_spider_fw.DBSerivce import DBService


db_name = 'aliexpress'
table_name = 'store_name'
table_title = 'category,store_name,store_href'
url_start = 'http://www.aliexpress.com/all-wholesale-products.html?spm=2114.11010108.22.1.wucNxZ'
connect_dict = {'host': 'localhost', 'user': 'root', 'passwd': '', 'charset': 'utf8'}

# now,the next is spider script
db_server = DBService(dbName=db_name, tableName=table_name, **connect_dict)
# if create table for store result in mysql , no need to be changed
if not db_server.isTableExist():
    db_server.createTable(tableTitle=table_title.split(','))


class Handler(BaseHandler):
    crawl_config = {
        # 'proxy': '10.10.10.10:80',
        'headers': {
            'User-Agent': 'User-Agent:Mozilla/5.0 (Windows NT 6.1; rv:2.0.1) Gecko/20100101 Firefox/4.0.1'
        }
    }

    @every(minutes=24 * 60)
    def on_start(self):
        self.crawl(url_start, callback=self.step_first)

    @config(age=2 * 24 * 60 * 60)
    def step_first(self, response):
        d = response.doc
        for t in d('.sub-item-cont.util-clearfix>li>a').items():
            cate=t.text()
            self.crawl(t.attr.href, callback=self.step_second,save={'cate':cate})

    def step_second(self,response):
        d=response.doc
        for t in d('.ui-pagination-navi.util-left a').items():
            self.crawl(t.attr.href, callback=self.step_second)
        return [
            [
                response.save['cate'],
                t.attr['title'],
                t.attr.href
            ]
            for t in d('.store').items()
        ]

    # over ride method for result store to mysql
    def on_result(self, result):
        if result:
            db_server.data2DB(data=result)
        else:
            print u'result-->return None'